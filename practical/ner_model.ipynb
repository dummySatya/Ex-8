{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from - https://www.clips.uantwerpen.be/conll2000/chunking/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_path):\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentence = []\n",
    "        pos_tags = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":  # Sentence boundary\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    tags.append(pos_tags)\n",
    "                    sentence = []\n",
    "                    pos_tags = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:  # Ensure the line has at least word and POS tag\n",
    "                    word, pos_tag = parts[0], parts[1]\n",
    "                    sentence.append(word)\n",
    "                    pos_tags.append(pos_tag)\n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "            tags.append(pos_tags)\n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/train.txt\"\n",
    "sentences, pos_tags = prepare_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab = {word: idx for idx, word in enumerate(set(w for s in sentences for w in s), start=1)} # word to index mapping\n",
    "word_vocab[\"<PAD>\"] = 0  # For padding\n",
    "word_vocab[\"<UNK>\"] = len(word_vocab)  # For unknown words\n",
    "\n",
    "tag_vocab = {tag: idx for idx, tag in enumerate(set(t for ts in pos_tags for t in ts))} # tag to index mapping\n",
    "idx2tag = {tag_vocab[tag] : tag for tag in tag_vocab.keys()} # index to tag mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19124, 44)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vocab),len(tag_vocab) # total words and total tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(sentences, tags, word_vocab, tag_vocab):\n",
    "    encoded_sentences = [[word_vocab.get(w, word_vocab[\"<UNK>\"]) for w in s] for s in sentences]\n",
    "    encoded_tags = [[tag_vocab[t] for t in ts] for ts in tags]\n",
    "    return encoded_sentences, encoded_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = \"./data/test.txt\"\n",
    "t_sentences, t_pos_tags = prepare_data(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = encode_data(sentences, pos_tags, word_vocab, tag_vocab)\n",
    "X_test, y_test = encode_data(t_sentences,t_pos_tags,word_vocab,tag_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8936, 2012)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(data, pad_value):\n",
    "    return pad_sequence([torch.tensor(seq) for seq in data], batch_first=True, padding_value=pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, word_vocab[\"<PAD>\"])\n",
    "y_train = pad_sequences(y_train, -1)  # Use -1 as the padding value for loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pad_sequences(X_test,word_vocab[\"<PAD>\"])\n",
    "y_test = pad_sequences(y_test,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8936, 78]), torch.Size([2012, 70]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8936, 78]), torch.Size([2012, 70]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERData(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index],self.y[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = NERData(X_train,y_train)\n",
    "testdata = NERData(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(traindata,batch_size = 32, shuffle= True)\n",
    "test_loader = DataLoader(testdata,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim=100, hidden_dim=128):\n",
    "        super(NERModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) \n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERModel(vocab_size=len(word_vocab),tagset_size=len(tag_vocab))\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1) # -1 to ignore the padded vals\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 449.1815\n",
      "Epoch 2, Loss: 194.3661\n",
      "Epoch 3, Loss: 129.3869\n",
      "Epoch 4, Loss: 94.3600\n",
      "Epoch 5, Loss: 71.6262\n",
      "Epoch 6, Loss: 55.4726\n",
      "Epoch 7, Loss: 43.0991\n",
      "Epoch 8, Loss: 33.6133\n",
      "Epoch 9, Loss: 26.2157\n",
      "Epoch 10, Loss: 20.3652\n",
      "Epoch 11, Loss: 15.8403\n",
      "Epoch 12, Loss: 12.2428\n",
      "Epoch 13, Loss: 9.4634\n",
      "Epoch 14, Loss: 7.3254\n",
      "Epoch 15, Loss: 5.7133\n",
      "Epoch 16, Loss: 4.4356\n",
      "Epoch 17, Loss: 3.4665\n",
      "Epoch 18, Loss: 2.7486\n",
      "Epoch 19, Loss: 2.2216\n",
      "Epoch 20, Loss: 1.8028\n",
      "Epoch 21, Loss: 1.5176\n",
      "Epoch 22, Loss: 1.2982\n",
      "Epoch 23, Loss: 1.1716\n",
      "Epoch 24, Loss: 1.0853\n",
      "Epoch 25, Loss: 1.0233\n",
      "Epoch 26, Loss: 0.9383\n",
      "Epoch 27, Loss: 0.8500\n",
      "Epoch 28, Loss: 0.7912\n",
      "Epoch 29, Loss: 0.7592\n",
      "Epoch 30, Loss: 0.7250\n",
      "Epoch 31, Loss: 0.7191\n",
      "Epoch 32, Loss: 0.6924\n",
      "Epoch 33, Loss: 0.6415\n",
      "Epoch 34, Loss: 0.6619\n",
      "Epoch 35, Loss: 1.6962\n",
      "Epoch 36, Loss: 1.4112\n",
      "Epoch 37, Loss: 0.7242\n",
      "Epoch 38, Loss: 0.5967\n",
      "Epoch 39, Loss: 0.5694\n",
      "Epoch 40, Loss: 0.5738\n",
      "Epoch 41, Loss: 0.5574\n",
      "Epoch 42, Loss: 0.5406\n",
      "Epoch 43, Loss: 0.5413\n",
      "Epoch 44, Loss: 0.5284\n",
      "Epoch 45, Loss: 0.5470\n",
      "Epoch 46, Loss: 0.5315\n",
      "Epoch 47, Loss: 0.5376\n",
      "Epoch 48, Loss: 0.5341\n",
      "Epoch 49, Loss: 0.5290\n",
      "Epoch 50, Loss: 0.5305\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x,y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        outputs = outputs.view(-1,outputs.shape[-1])\n",
    "        y = y.view(-1)\n",
    "\n",
    "        loss = criterion(outputs,y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"saved_model/ner_model.pth\"\n",
    "torch.save(model.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x783268b7b610>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [],[]\n",
    "with torch.no_grad():\n",
    "    for x,y in test_loader:\n",
    "        outputs = model(x)\n",
    "        preds = torch.argmax(outputs,dim = -1)\n",
    "\n",
    "        all_preds.extend(preds.view(-1).tolist())\n",
    "        all_labels.extend(y.view(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered labels length: 47377\n",
      "Filtered preds length: 47377\n"
     ]
    }
   ],
   "source": [
    "# This is done to remove the -1 (paddings)\n",
    "valid_indices = [i for i, label in enumerate(all_labels) if label != -1]\n",
    "filtered_labels = [all_labels[i] for i in valid_indices]\n",
    "filtered_preds = [all_preds[i] for i in valid_indices]\n",
    "\n",
    "print(f\"Filtered labels length: {len(filtered_labels)}\")\n",
    "print(f\"Filtered preds length: {len(filtered_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91      1354\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.99      1.00      1.00       434\n",
      "           3       1.00      0.50      0.67         4\n",
      "           4       0.84      0.57      0.68       130\n",
      "           5       1.00      1.00      1.00      1178\n",
      "           6       1.00      0.99      1.00       814\n",
      "           7       0.14      0.08      0.11        12\n",
      "           8       0.93      0.78      0.85       728\n",
      "           9       0.97      0.91      0.94      1918\n",
      "          10       0.71      0.86      0.78       202\n",
      "          11       1.00      1.00      1.00      2390\n",
      "          13       0.99      0.94      0.96        77\n",
      "          14       0.97      0.89      0.93      6642\n",
      "          15       0.97      0.90      0.93       913\n",
      "          16       1.00      0.99      1.00       316\n",
      "          17       0.91      0.94      0.92      1679\n",
      "          18       0.80      0.95      0.87      4806\n",
      "          19       0.66      0.68      0.67        71\n",
      "          20       0.92      0.90      0.91       539\n",
      "          21       0.96      1.00      0.98        48\n",
      "          22       1.00      1.00      1.00      1214\n",
      "          23       1.00      1.00      1.00       323\n",
      "          24       1.00      0.30      0.46        10\n",
      "          25       0.99      0.99      0.99      4020\n",
      "          26       1.00      1.00      1.00       110\n",
      "          27       0.78      0.85      0.81      1104\n",
      "          28       1.00      1.00      1.00        77\n",
      "          29       1.00      1.00      1.00         4\n",
      "          30       1.00      1.00      1.00        77\n",
      "          31       0.97      0.86      0.91      3034\n",
      "          32       1.00      0.98      0.99        49\n",
      "          33       1.00      1.00      1.00       384\n",
      "          34       1.00      1.00      1.00       470\n",
      "          35       1.00      1.00      1.00       238\n",
      "          36       0.77      0.88      0.82      2964\n",
      "          37       0.95      0.90      0.93      1269\n",
      "          38       1.00      0.99      0.99        93\n",
      "          39       0.88      0.84      0.86       202\n",
      "          40       0.98      0.98      0.98      5071\n",
      "          41       1.00      1.00      1.00       421\n",
      "          42       1.00      1.00      1.00      1975\n",
      "          43       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           0.93     47377\n",
      "   macro avg       0.93      0.88      0.90     47377\n",
      "weighted avg       0.94      0.93      0.93     47377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(filtered_labels,filtered_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy - 93%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The quick fox jumped over the dog\"\n",
    "sentence = sentence.split() # Splits the input sentence into words\n",
    "inp = torch.tensor([word_vocab[word] for word in sentence]) \n",
    "# Maps each sentence to it's integer representation and convert to tensor\n",
    "outputs = model(inp) # Input is fed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8981e+00, -3.9388e+00, -4.6404e+00, -7.6772e+00, -7.1070e+00,\n",
       "         -6.2773e+00, -2.5990e+00, -4.9538e+00, -1.7141e+00, -5.6245e+00,\n",
       "         -6.8659e+00, -2.5877e+00, -5.6188e+00, -2.4715e+00,  1.7577e+00,\n",
       "         -3.4109e+00, -4.0954e+00, -2.7489e+00,  7.0745e+00, -5.7531e-01,\n",
       "         -3.3659e+00, -4.8864e+00, -4.9675e+00, -3.9496e+00, -4.0211e+00,\n",
       "          2.1439e+01, -1.1646e+01, -1.9131e+00, -1.0769e+01, -6.9047e+00,\n",
       "         -4.9124e+00, -2.9919e+00, -2.2390e-02, -2.6679e+00, -7.1509e+00,\n",
       "         -1.2011e+01,  6.4214e+00, -6.6138e+00, -1.2612e+01, -4.0574e-01,\n",
       "         -1.7654e+00, -2.4012e+00, -2.5922e+00, -1.1253e+01],\n",
       "        [ 4.1341e+00, -2.0355e+00, -1.0825e+01, -6.3261e-01,  2.7597e+00,\n",
       "         -8.6108e+00, -5.1579e+00, -2.3910e+00, -6.8450e+00,  2.2216e+00,\n",
       "         -5.3521e-01, -5.9292e+00, -8.0406e+00, -3.2867e+00,  6.4286e+00,\n",
       "          1.3817e+00, -6.8315e+00, -6.2847e+00,  5.9865e+00, -3.9262e+00,\n",
       "         -1.2559e+01, -9.5616e+00, -6.9991e+00, -4.5441e+00, -3.7462e+00,\n",
       "         -1.7486e+00, -8.3793e+00, -2.7878e+00, -7.7633e+00, -8.7890e+00,\n",
       "         -7.3326e+00,  2.5516e+00,  1.4998e+00, -9.4093e+00, -1.1718e+01,\n",
       "         -8.2888e+00,  1.6032e+01, -9.2233e+00, -1.2208e+01,  7.0021e-01,\n",
       "         -4.8389e+00, -9.5898e+00, -3.8897e+00, -9.6798e+00],\n",
       "        [-6.7115e+00,  2.1446e-01, -1.0394e+01, -9.8692e-01,  2.8919e+00,\n",
       "         -3.7365e+00,  7.0110e-01,  1.0372e-01, -1.3018e-01, -5.7264e+00,\n",
       "          1.9484e-01, -3.9118e+00, -3.5223e+00, -4.4340e+00,  1.8876e+01,\n",
       "         -1.5521e+00, -8.3430e+00, -2.6183e+00,  6.5720e-01, -1.3824e+00,\n",
       "          9.7493e-01, -1.1386e+01, -8.7899e+00, -6.6231e+00, -2.8402e+00,\n",
       "         -8.2308e+00, -1.0711e+01, -6.5564e+00,  3.7777e+00, -9.1813e+00,\n",
       "         -5.7727e+00,  4.4320e+00, -3.8317e+00, -5.5665e+00, -2.2955e+00,\n",
       "         -5.3031e+00,  3.5715e+00, -1.0012e+01, -3.6195e+00, -1.7099e+00,\n",
       "          4.7098e-01, -3.0987e-01,  9.4928e-01, -5.1216e+00],\n",
       "        [-2.6343e+00, -1.2829e+00, -1.0537e+01,  5.4109e+00, -8.0506e-01,\n",
       "         -4.6836e+00, -1.9787e+00,  2.7049e-01, -8.6084e+00,  3.8615e+00,\n",
       "          2.8027e+00, -3.2968e+00, -5.1094e+00, -4.2094e+00,  4.6650e+00,\n",
       "          6.8890e+00, -8.7011e+00,  2.6588e+01,  5.1335e+00, -1.0336e+01,\n",
       "         -4.3536e-01, -2.7208e+00, -5.0050e+00,  2.0431e+00, -2.6446e+00,\n",
       "         -9.7369e+00,  2.5230e-01,  2.0304e+00, -4.7864e+00, -5.2500e+00,\n",
       "         -4.4577e+00, -8.9967e-01,  2.7492e+00, -1.6869e+00, -1.9544e+00,\n",
       "          1.2791e+00,  1.4491e+00, -6.8324e+00, -7.2113e+00, -4.6674e+00,\n",
       "         -3.7678e+00, -1.3436e+01, -5.7529e+00, -3.9124e+00],\n",
       "        [ 5.6626e+00, -7.1639e+00, -2.8808e+00, -1.6152e+00, -4.9570e+00,\n",
       "          1.3959e+00, -3.4854e+00, -4.5019e+00, -4.9936e+00, -1.6510e-01,\n",
       "          1.1083e+00, -8.3135e+00, -6.1721e+00, -1.6974e+01, -4.5196e+00,\n",
       "          3.4803e+00, -9.2917e+00,  6.9838e-01, -1.8121e+00, -5.5775e-01,\n",
       "         -8.4228e-01,  7.8655e-01, -2.5387e+00, -4.9508e+00, -2.4856e+00,\n",
       "         -8.2819e-01, -7.6928e+00,  1.7584e+00, -3.4529e+00, -2.3042e+00,\n",
       "          1.2532e-01, -3.4369e+00, -3.0384e+00,  2.4983e+00, -6.9187e+00,\n",
       "         -5.3054e+00,  6.7980e+00, -3.2221e+00, -7.8959e+00,  1.8672e+00,\n",
       "          2.0184e+01, -3.9639e-01, -7.4222e+00, -4.2395e+00],\n",
       "        [-2.3081e+00, -8.8205e-01, -5.6584e+00, -1.8110e+00, -3.4060e+00,\n",
       "         -5.6124e+00, -3.9693e+00, -7.1781e+00, -7.7662e+00, -5.8330e+00,\n",
       "         -9.0610e+00, -1.6980e+00, -7.7350e+00, -5.4098e-02, -6.2905e-01,\n",
       "         -2.8919e+00, -5.8918e+00, -1.0323e+01,  6.7478e+00,  2.4414e+00,\n",
       "         -4.6836e+00, -7.3429e+00, -4.1232e+00, -1.8190e+00, -3.0687e+00,\n",
       "          2.2391e+01, -1.5924e+01, -2.8652e+00, -1.1001e+01, -9.2674e+00,\n",
       "         -3.3676e+00, -1.0292e+00,  1.2572e+00,  1.2375e-01, -1.1366e+01,\n",
       "         -1.3360e+01,  8.5646e+00, -7.6247e+00, -1.3958e+01,  3.3076e+00,\n",
       "          5.9262e+00,  2.2693e+00, -7.9449e-01, -1.0332e+01],\n",
       "        [-7.8025e+00, -3.4683e+00, -4.7931e+00,  1.3027e-03,  4.5850e+00,\n",
       "         -4.3759e+00, -4.9149e+00, -5.6602e+00,  7.4131e-01,  1.5858e+00,\n",
       "         -2.3961e+00, -2.4753e+00, -1.1190e+01,  2.4128e+00,  1.6945e+01,\n",
       "         -1.1830e+01, -8.5369e+00, -1.7349e+01,  1.4328e+01, -3.1715e+00,\n",
       "         -8.7281e+00, -1.3678e+01, -6.5953e+00, -6.7987e+00, -1.2806e+00,\n",
       "         -5.4738e+00, -1.1044e+01, -2.3680e+00, -5.2597e+00, -7.6739e+00,\n",
       "         -5.2505e+00, -7.5454e-01, -1.5731e+00, -5.6173e+00, -9.3639e+00,\n",
       "         -9.8347e+00,  9.0447e+00, -6.2306e+00, -5.5932e+00,  3.9840e-01,\n",
       "         -8.2901e+00, -2.9066e+00, -5.6118e+00, -8.2469e+00]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 44])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input a single vector of 7 words (numerical representation) so each word would have its probabilities along all the classes (44 tags).  \n",
    "Now we need to find which class has highest probability in for each word and for that we use argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.argmax(outputs,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25, 36, 14, 17, 40, 25, 14])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above tensor is basically the list of indices of the max probabilities among the 44 classes for each of the word. And since the indices are what the classes/tags are, we can directly map it with our tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.tolist() # Convert to python list\n",
    "tags = [idx2tag[idx] for idx in output] # Map the indices to class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT', 'JJ', 'NN', 'VBD', 'IN', 'DT', 'NN']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The   - DT    - Determiner    - Correct  \n",
    "- quick - JJ    - Adjective     - Correct  \n",
    "- fox   - NN    - Noun          - Correct  \n",
    "- jump  - VBD   - Verb(Past)    - Correct  \n",
    "- over  - IN    - Preposition   - Correct  \n",
    "- the   - DT    - Determiner    - Correct  \n",
    "- dog   - NN    - Noun          - Correct  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ouput(sentence):\n",
    "    sentence = sentence.split() # Splits the input sentence into words\n",
    "    inp = torch.tensor([word_vocab[word] for word in sentence]) \n",
    "    # Maps each sentence to it's integer representation and convert to tensor\n",
    "    outputs = model(inp) # Input is fed into the model\n",
    "    output = torch.argmax(outputs,dim=-1)\n",
    "    output = output.tolist() # Convert to python list\n",
    "    tags = [idx2tag[idx] for idx in output] # Map the indices to class labels\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRP', 'VBZ', 'NN', 'DT', 'NN']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = \"She is reading a book\"\n",
    "out1 = sample_ouput(sent1)\n",
    "out1\n",
    "# Expected : ['PRP', 'VBZ', 'VBG', 'DT', 'NN'] (4/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRP', 'VBP', 'RB', 'VBN', 'JJ', 'DT', 'JJ', 'NN']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2 = \"I have never seen such a beautiful view\"\n",
    "out2 = sample_ouput(sent2)\n",
    "out2\n",
    "# Expected : ['PRP', 'VBP', 'RB', 'VBN', 'JJ', 'DT', 'JJ', 'NN'] (8/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MD', 'PRP', 'VB', 'PRP', 'IN', 'DT', 'NN']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3 = \"can you help me with this project\"\n",
    "out3 = sample_ouput(sent3)\n",
    "out3\n",
    "# Expected : ['MD', 'PRP', 'VB', 'PRP', 'IN', 'DT', 'NN'] (7/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT', 'NNS', 'VBD', 'VBG', 'IN', 'DT', 'NN']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 = \"The children were playing in the park\"\n",
    "out4 = sample_ouput(sent4)\n",
    "out4\n",
    "# Expected : ['DT', 'NNS', 'VBD', 'VBG', 'IN', 'DT', 'NN'] (7/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
