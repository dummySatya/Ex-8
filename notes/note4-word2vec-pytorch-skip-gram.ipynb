{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "# We will use Shakespeare Sonnet 2\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "# we should tokenize the input, but we will ignore that for now\n",
    "# build a list of tuples.\n",
    "# Each tuple is ([ word_i-CONTEXT_SIZE, ..., word_i-1 ], target word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When',\n",
       " 'forty',\n",
       " 'winters',\n",
       " 'shall',\n",
       " 'besiege',\n",
       " 'thy',\n",
       " 'brow,',\n",
       " 'And',\n",
       " 'dig',\n",
       " 'deep',\n",
       " 'trenches',\n",
       " 'in',\n",
       " 'thy',\n",
       " \"beauty's\",\n",
       " 'field,',\n",
       " 'Thy',\n",
       " \"youth's\",\n",
       " 'proud',\n",
       " 'livery',\n",
       " 'so',\n",
       " 'gazed',\n",
       " 'on',\n",
       " 'now,',\n",
       " 'Will',\n",
       " 'be',\n",
       " 'a',\n",
       " \"totter'd\",\n",
       " 'weed',\n",
       " 'of',\n",
       " 'small',\n",
       " 'worth',\n",
       " 'held:',\n",
       " 'Then',\n",
       " 'being',\n",
       " 'asked,',\n",
       " 'where',\n",
       " 'all',\n",
       " 'thy',\n",
       " 'beauty',\n",
       " 'lies,',\n",
       " 'Where',\n",
       " 'all',\n",
       " 'the',\n",
       " 'treasure',\n",
       " 'of',\n",
       " 'thy',\n",
       " 'lusty',\n",
       " 'days;',\n",
       " 'To',\n",
       " 'say,',\n",
       " 'within',\n",
       " 'thine',\n",
       " 'own',\n",
       " 'deep',\n",
       " 'sunken',\n",
       " 'eyes,',\n",
       " 'Were',\n",
       " 'an',\n",
       " 'all-eating',\n",
       " 'shame,',\n",
       " 'and',\n",
       " 'thriftless',\n",
       " 'praise.',\n",
       " 'How',\n",
       " 'much',\n",
       " 'more',\n",
       " 'praise',\n",
       " \"deserv'd\",\n",
       " 'thy',\n",
       " \"beauty's\",\n",
       " 'use,',\n",
       " 'If',\n",
       " 'thou',\n",
       " 'couldst',\n",
       " 'answer',\n",
       " \"'This\",\n",
       " 'fair',\n",
       " 'child',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'Shall',\n",
       " 'sum',\n",
       " 'my',\n",
       " 'count,',\n",
       " 'and',\n",
       " 'make',\n",
       " 'my',\n",
       " 'old',\n",
       " \"excuse,'\",\n",
       " 'Proving',\n",
       " 'his',\n",
       " 'beauty',\n",
       " 'by',\n",
       " 'succession',\n",
       " 'thine!',\n",
       " 'This',\n",
       " 'were',\n",
       " 'to',\n",
       " 'be',\n",
       " 'new',\n",
       " 'made',\n",
       " 'when',\n",
       " 'thou',\n",
       " 'art',\n",
       " 'old,',\n",
       " 'And',\n",
       " 'see',\n",
       " 'thy',\n",
       " 'blood',\n",
       " 'warm',\n",
       " 'when',\n",
       " 'thou',\n",
       " \"feel'st\",\n",
       " 'it',\n",
       " 'cold.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['forty', 'When'], 'winters'), (['winters', 'forty'], 'shall'), (['shall', 'winters'], 'besiege')]\n"
     ]
    }
   ],
   "source": [
    "ngrams = [\n",
    "    (\n",
    "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
    "        test_sentence[i]\n",
    "    )\n",
    "    for i in range(CONTEXT_SIZE, len(test_sentence))\n",
    "]\n",
    "# Print the first 3, just so you can see what they look like.\n",
    "print(ngrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new': 0,\n",
       " 'so': 1,\n",
       " 'lusty': 2,\n",
       " 'Shall': 3,\n",
       " 'Proving': 4,\n",
       " 'thine': 5,\n",
       " 'worth': 6,\n",
       " 'shall': 7,\n",
       " 'shame,': 8,\n",
       " 'were': 9,\n",
       " 'lies,': 10,\n",
       " 'mine': 11,\n",
       " 'by': 12,\n",
       " 'cold.': 13,\n",
       " 'held:': 14,\n",
       " 'and': 15,\n",
       " 'sum': 16,\n",
       " 'praise': 17,\n",
       " 'within': 18,\n",
       " 'forty': 19,\n",
       " 'to': 20,\n",
       " 'on': 21,\n",
       " 'in': 22,\n",
       " 'winters': 23,\n",
       " 'blood': 24,\n",
       " 'thriftless': 25,\n",
       " 'old': 26,\n",
       " \"feel'st\": 27,\n",
       " 'days;': 28,\n",
       " 'brow,': 29,\n",
       " 'more': 30,\n",
       " \"excuse,'\": 31,\n",
       " \"beauty's\": 32,\n",
       " 'my': 33,\n",
       " 'where': 34,\n",
       " 'warm': 35,\n",
       " 'thy': 36,\n",
       " 'being': 37,\n",
       " 'see': 38,\n",
       " 'Thy': 39,\n",
       " \"totter'd\": 40,\n",
       " 'Will': 41,\n",
       " 'own': 42,\n",
       " 'eyes,': 43,\n",
       " 'gazed': 44,\n",
       " 'asked,': 45,\n",
       " 'How': 46,\n",
       " 'make': 47,\n",
       " 'sunken': 48,\n",
       " 'dig': 49,\n",
       " 'say,': 50,\n",
       " 'when': 51,\n",
       " 'beauty': 52,\n",
       " 'child': 53,\n",
       " 'besiege': 54,\n",
       " 'much': 55,\n",
       " 'answer': 56,\n",
       " 'Were': 57,\n",
       " 'his': 58,\n",
       " 'all-eating': 59,\n",
       " 'field,': 60,\n",
       " 'the': 61,\n",
       " 'praise.': 62,\n",
       " 'art': 63,\n",
       " \"deserv'd\": 64,\n",
       " 'a': 65,\n",
       " 'succession': 66,\n",
       " 'trenches': 67,\n",
       " 'small': 68,\n",
       " \"youth's\": 69,\n",
       " 'it': 70,\n",
       " 'an': 71,\n",
       " 'of': 72,\n",
       " 'now,': 73,\n",
       " 'count,': 74,\n",
       " 'If': 75,\n",
       " 'Then': 76,\n",
       " 'fair': 77,\n",
       " 'Where': 78,\n",
       " 'proud': 79,\n",
       " 'When': 80,\n",
       " 'couldst': 81,\n",
       " 'made': 82,\n",
       " 'weed': 83,\n",
       " 'old,': 84,\n",
       " 'To': 85,\n",
       " 'be': 86,\n",
       " 'thou': 87,\n",
       " 'This': 88,\n",
       " 'use,': 89,\n",
       " 'thine!': 90,\n",
       " 'treasure': 91,\n",
       " 'And': 92,\n",
       " 'livery': 93,\n",
       " 'all': 94,\n",
       " \"'This\": 95,\n",
       " 'deep': 96}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramLangModel(nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim, context_size):\n",
    "        super(SkipGramLangModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1,-1))\n",
    "        out = torch.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        logs_probs = torch.log_softmax(out, dim = 1)\n",
    "        return logs_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satya-tt0492/anaconda3/envs/ex5/lib/python3.9/site-packages/onnxscript/converter.py:820: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/home/satya-tt0492/anaconda3/envs/ex5/lib/python3.9/site-packages/onnxscript/converter.py:820: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_func = nn.NLLLoss()\n",
    "model = SkipGramLangModel(len(vocab),EMBEDDING_DIM,CONTEXT_SIZE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[518.4590497016907, 516.049512386322, 513.6575908660889, 511.2817862033844, 508.92097520828247, 506.57483959198, 504.2426676750183, 501.92250752449036, 499.61424946784973, 497.3170645236969]\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(10):\n",
    "    total_loss = 0\n",
    "    for context,target in ngrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_idxs)\n",
    "        loss = loss_func(log_probs,torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5911,  0.6573,  1.3298, -0.4835, -0.3081, -1.0619,  0.6875, -0.2479,\n",
       "         0.4607, -0.6335], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.weight[word_to_ix[\"beauty\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
