{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"An explosion targeting a tourist bus has injured at least 16 people near the Grand Egyptian Museum, \n",
    "next to the pyramids in Giza, security sources say E.U.\n",
    "\n",
    "South African tourists are among the injured. Most of those hurt suffered minor injuries, \n",
    "while three were treated in hospital, N.A.T.O. say.\n",
    "\n",
    "http://localhost:8888/notebooks/Text%20preprocessing.ipynb\n",
    "\n",
    "@nickname of twitter user and his email is email@gmail.com . \n",
    "\n",
    "A device went off close to the museum fence as the bus was passing on 16/02/2012.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/satya-\n",
      "[nltk_data]     tt0492/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'explosion',\n",
       " 'targeting',\n",
       " 'a',\n",
       " 'tourist',\n",
       " 'bus',\n",
       " 'has',\n",
       " 'injured',\n",
       " 'at',\n",
       " 'least',\n",
       " '16',\n",
       " 'people',\n",
       " 'near',\n",
       " 'the',\n",
       " 'grand',\n",
       " 'egyptian',\n",
       " 'museum',\n",
       " ',',\n",
       " 'next',\n",
       " 'to',\n",
       " 'the',\n",
       " 'pyramids',\n",
       " 'in',\n",
       " 'giza',\n",
       " ',',\n",
       " 'security',\n",
       " 'sources',\n",
       " 'say',\n",
       " 'e.u',\n",
       " '.',\n",
       " 'south',\n",
       " 'african',\n",
       " 'tourists',\n",
       " 'are',\n",
       " 'among',\n",
       " 'the',\n",
       " 'injured',\n",
       " '.',\n",
       " 'most',\n",
       " 'of',\n",
       " 'those',\n",
       " 'hurt',\n",
       " 'suffered',\n",
       " 'minor',\n",
       " 'injuries',\n",
       " ',',\n",
       " 'while',\n",
       " 'three',\n",
       " 'were',\n",
       " 'treated',\n",
       " 'in',\n",
       " 'hospital',\n",
       " ',',\n",
       " 'n.a.t.o',\n",
       " '.',\n",
       " 'say',\n",
       " '.',\n",
       " 'http',\n",
       " ':',\n",
       " '//localhost:8888/notebooks/text',\n",
       " '%',\n",
       " '20preprocessing.ipynb',\n",
       " '@',\n",
       " 'nickname',\n",
       " 'of',\n",
       " 'twitter',\n",
       " 'user',\n",
       " 'and',\n",
       " 'his',\n",
       " 'email',\n",
       " 'is',\n",
       " 'email',\n",
       " '@',\n",
       " 'gmail.com',\n",
       " '.',\n",
       " 'a',\n",
       " 'device',\n",
       " 'went',\n",
       " 'off',\n",
       " 'close',\n",
       " 'to',\n",
       " 'the',\n",
       " 'museum',\n",
       " 'fence',\n",
       " 'as',\n",
       " 'the',\n",
       " 'bus',\n",
       " 'was',\n",
       " 'passing',\n",
       " 'on',\n",
       " '16/02/2012',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "nltk_words = word_tokenize(text)\n",
    "nltk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "an explosion targeting a tourist bus has injured at least 16 people near the grand egyptian museum, \n",
       "next to the pyramids in giza, security sources say e.u.\n",
       "\n",
       "south african tourists are among the injured. most of those hurt suffered minor injuries, \n",
       "while three were treated in hospital, n.a.t.o. say.\n",
       "\n",
       "http://localhost:8888/notebooks/text%20preprocessing.ipynb\n",
       "\n",
       "@nickname of twitter user and his email is email@gmail.com . \n",
       "\n",
       "a device went off close to the museum fence as the bus was passing on 16/02/2012."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'explosion',\n",
       " 'targeting',\n",
       " 'a',\n",
       " 'tourist',\n",
       " 'bus',\n",
       " 'has',\n",
       " 'injured',\n",
       " 'at',\n",
       " 'least',\n",
       " '16',\n",
       " 'people',\n",
       " 'near',\n",
       " 'the',\n",
       " 'grand',\n",
       " 'egyptian',\n",
       " 'museum',\n",
       " ',',\n",
       " '\\n',\n",
       " 'next',\n",
       " 'to',\n",
       " 'the',\n",
       " 'pyramids',\n",
       " 'in',\n",
       " 'giza',\n",
       " ',',\n",
       " 'security',\n",
       " 'sources',\n",
       " 'say',\n",
       " 'e.u',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'south',\n",
       " 'african',\n",
       " 'tourists',\n",
       " 'are',\n",
       " 'among',\n",
       " 'the',\n",
       " 'injured',\n",
       " '.',\n",
       " 'most',\n",
       " 'of',\n",
       " 'those',\n",
       " 'hurt',\n",
       " 'suffered',\n",
       " 'minor',\n",
       " 'injuries',\n",
       " ',',\n",
       " '\\n',\n",
       " 'while',\n",
       " 'three',\n",
       " 'were',\n",
       " 'treated',\n",
       " 'in',\n",
       " 'hospital',\n",
       " ',',\n",
       " 'n.a.t.o',\n",
       " '.',\n",
       " 'say',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'http://localhost:8888',\n",
       " '/',\n",
       " 'notebooks',\n",
       " '/',\n",
       " 'text%20preprocessing.ipynb',\n",
       " '\\n\\n',\n",
       " '@nickname',\n",
       " 'of',\n",
       " 'twitter',\n",
       " 'user',\n",
       " 'and',\n",
       " 'his',\n",
       " 'email',\n",
       " 'is',\n",
       " 'email@gmail.com',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'a',\n",
       " 'device',\n",
       " 'went',\n",
       " 'off',\n",
       " 'close',\n",
       " 'to',\n",
       " 'the',\n",
       " 'museum',\n",
       " 'fence',\n",
       " 'as',\n",
       " 'the',\n",
       " 'bus',\n",
       " 'was',\n",
       " 'passing',\n",
       " 'on',\n",
       " '16/02/2012',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_words = [token.text for token in doc]\n",
    "spacy_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diff btw nltk and spacy is that spacy was able to handle emails and websites better while nltk did well with /n and all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuations removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'explosion',\n",
       " 'targeting',\n",
       " 'a',\n",
       " 'tourist',\n",
       " 'bus',\n",
       " 'has',\n",
       " 'injured',\n",
       " 'at',\n",
       " 'least',\n",
       " '16',\n",
       " 'people',\n",
       " 'near',\n",
       " 'the',\n",
       " 'grand',\n",
       " 'egyptian',\n",
       " 'museum',\n",
       " '\\n',\n",
       " 'next',\n",
       " 'to',\n",
       " 'the',\n",
       " 'pyramids',\n",
       " 'in',\n",
       " 'giza',\n",
       " 'security',\n",
       " 'sources',\n",
       " 'say',\n",
       " 'e.u',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'south',\n",
       " 'african',\n",
       " 'tourists',\n",
       " 'are',\n",
       " 'among',\n",
       " 'the',\n",
       " 'injured',\n",
       " 'most',\n",
       " 'of',\n",
       " 'those',\n",
       " 'hurt',\n",
       " 'suffered',\n",
       " 'minor',\n",
       " 'injuries',\n",
       " '\\n',\n",
       " 'while',\n",
       " 'three',\n",
       " 'were',\n",
       " 'treated',\n",
       " 'in',\n",
       " 'hospital',\n",
       " 'n.a.t.o',\n",
       " '.',\n",
       " 'say',\n",
       " '\\n\\n',\n",
       " 'http://localhost:8888',\n",
       " '/',\n",
       " 'notebooks',\n",
       " 'text%20preprocessing.ipynb',\n",
       " '\\n\\n',\n",
       " '@nickname',\n",
       " 'of',\n",
       " 'twitter',\n",
       " 'user',\n",
       " 'and',\n",
       " 'his',\n",
       " 'email',\n",
       " 'is',\n",
       " 'email@gmail.com',\n",
       " '\\n\\n',\n",
       " 'a',\n",
       " 'device',\n",
       " 'went',\n",
       " 'off',\n",
       " 'close',\n",
       " 'to',\n",
       " 'the',\n",
       " 'museum',\n",
       " 'fence',\n",
       " 'as',\n",
       " 'the',\n",
       " 'bus',\n",
       " 'was',\n",
       " 'passing',\n",
       " 'on',\n",
       " '16/02/2012']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_without_punct_spacy = [t.text for t in doc if t.pos_ != 'PUNCT']\n",
    "tokens_without_punct_spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/satya-\n",
      "[nltk_data]     tt0492/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not done in POS tagging\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "len(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explosion',\n",
       " 'targeting',\n",
       " 'tourist',\n",
       " 'bus',\n",
       " 'injured',\n",
       " '16',\n",
       " 'people',\n",
       " 'near',\n",
       " 'grand',\n",
       " 'egyptian',\n",
       " 'museum',\n",
       " ',',\n",
       " '\\n',\n",
       " 'pyramids',\n",
       " 'giza',\n",
       " ',',\n",
       " 'security',\n",
       " 'sources',\n",
       " 'e.u',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'south',\n",
       " 'african',\n",
       " 'tourists',\n",
       " 'injured',\n",
       " '.',\n",
       " 'hurt',\n",
       " 'suffered',\n",
       " 'minor',\n",
       " 'injuries',\n",
       " ',',\n",
       " '\\n',\n",
       " 'treated',\n",
       " 'hospital',\n",
       " ',',\n",
       " 'n.a.t.o',\n",
       " '.',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'http://localhost:8888',\n",
       " '/',\n",
       " 'notebooks',\n",
       " '/',\n",
       " 'text%20preprocessing.ipynb',\n",
       " '\\n\\n',\n",
       " '@nickname',\n",
       " 'twitter',\n",
       " 'user',\n",
       " 'email',\n",
       " 'email@gmail.com',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'device',\n",
       " 'went',\n",
       " 'close',\n",
       " 'museum',\n",
       " 'fence',\n",
       " 'bus',\n",
       " 'passing',\n",
       " '16/02/2012',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spacy based\n",
    "text_without_stopwords = [word.text for word in nlp(text) if not word.is_stop]\n",
    "text_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/satya-\n",
      "[nltk_data]     tt0492/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nltk lemmatized text: an explosion targeting a tourist bus ha injured at least 16 people near the grand egyptian museum , next to the pyramid in giza , security source say e.u . south african tourist are among the injured . most of those hurt suffered minor injury , while three were treated in hospital , n.a.t.o . say . http : //localhost:8888/notebooks/text % 20preprocessing.ipynb @ nickname of twitter user and his email is email @ gmail.com . a device went off close to the museum fence a the bus wa passing on 16/02/2012 .'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()# vectorizing function to able to call on list of tokens\n",
    "lemmatize_words = np.vectorize(wordnet_lemmatizer.lemmatize)\n",
    "lemmatized_text = ' '.join(lemmatize_words(tokens))\n",
    "display(f\"nltk lemmatized text: {lemmatized_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spacy lemmatized text: an explosion target a tourist bus have injure at least 16 people near the grand egyptian museum , \\n next to the pyramid in giza , security source say e.u . \\n\\n south african tourist be among the injure . most of those hurt suffer minor injury , \\n while three be treat in hospital , n.a.t.o . say . \\n\\n http://localhost:8888 / notebook / text%20preprocessing.ipynb \\n\\n @nickname of twitter user and his email be email@gmail.com . \\n\\n a device go off close to the museum fence as the bus be pass on 16/02/2012 .'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spacy based\n",
    "lemmas = [t.lemma_ for t in nlp(text)]\n",
    "display(f\"Spacy lemmatized text: {' '.join(lemmas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy here is much better than nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
